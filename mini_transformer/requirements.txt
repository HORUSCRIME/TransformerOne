torch>=2.0.0
numpy>=1.24.0
pyyaml>=6.0

# Optional dependencies
# flash-attn>=2.0.0  # For FlashAttention (requires CUDA)
# bitsandbytes>=0.41.0  # For quantization
